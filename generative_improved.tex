%% This section describes the improved generative method. Only the differences between the original method (given in the previous section) and the new methhod are explained here. 

In this paper we also utilised a more advanced generative model, which we refer to as GM2. This model has three features which are different from the base model GM1. As for GM1, these are not a contribution of this paper and are described fully in \cite{kopicki2019ijrr}. For completeness, however, we briefly describe the three differences between GM2 and GM1. 

\subsection{Object View Model}\label{sec:representations.object}
The first difference is that the learning of grasp models is done per view, rather than per grasp. For a training grasp made on an object viewed from seven viewpoints, there will be seven grasp models learned. This enables grasps to generalise better when the testing object to be grasped is thick and is only seen from a single view. The view based models allow a greater role to be played by the hand shape model and this enables generated grasps to have fingers which `float' behind a back surface that cannot be seen by the robot.

\subsection{Clustering Contact Models}\label{sec:learning.clustering}

The second innovation is the ability to merge grasp models learned from different grasps. In the memory based scheme of GM1, the number of contact models $N_{\mathcal{M}}$ equals the product of the number of training grasps by the number of views. This has two undesirable properties. First, it means that generation of grasps for test objects rises linearly in the number of training grasps. Second, it limits the generalisation power of the contact models. We can overcome these problems by clustering the contact models from each training grasp. To do this we need a measure of the similarity between any pair of contact models. Recall that our contact models are probability densities represented as kernel density estimators. Thus, we need a distance metric in the space of probability densities of a given dimension.

One possibility is to employ Jensen-Shannon distance, but this is slow to evaluate. We therefore start by devising a simple and quick to compute asymmetric divergence. We then build on top of it a symmetric distance. Having obtained this distance measure we can employ our clustering method of choice, which in our case was affinity propagation \cite{frey2007clustering}. After clustering, we compute a cluster prototype as described in \cite{kopicki2019}.

\subsection{Improved Grasp Transfer and Inference}
GM2 utilises the same distance measure to transfer grasps when creating the query densities and also to evaluate candidate grasps. This has the effect of making the proposed grasps more conservative and thus closer to the demonstrated grasps in terms of the type of contacts made with the target object.

We now proceed to describe how we use these models to generate a data-set of 2 million simulated dexterous grasps.