This paper tackles dexterous grasping of a novel object given a single view. A generative-evaluative learning architecture (GEA) is presented. The generative model is acquired by data efficient learning from demonstration (LfD), and the evaluative model is trained in simulation, using grasps proposed by the generative model. When a novel object is presented the generative model proposes grasps, which are ranked by the evaluative model. Experiments show that this GEA architecture improves on both pure generative (GA) and pure evaluative (EA) architectures. On a challenging set of 49 real objects, GEA has a grasp success rate of 77.6\% relative to a pure GA (57.1\%). It is also shown that grasp optimisation using the EA fails to improve on grasps suggested by the GEA, worsening grasp success rate in simulation by 5\% against the baseline. These results provide support for generative-evaluative architectures for dexterous grasping.