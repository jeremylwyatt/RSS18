This paper tackles dexterous grasping of a novel object given a single view. A generative-evaluative learning architecture (GEA) is presented. The generative model (GM) is acquired by data efficient learning from demonstration (LfD), and the evaluative model (EM) is trained in simulation, using grasps proposed by the generative model. When a novel object is presented the generative model proposes grasps, which are ranked by the evaluative model. Experiments show that this GEA architecture improves on both pure generative model (GM). On a challenging set of 49 real objects, GEA has a grasp success rate of 77.6\% relative to a pure GM (57.1\%). It is also shown that grasp optimisation using the EM fails to improve on grasps suggested by the GEA, worsening grasp success rate in simulation by 4.8\% against the baseline. These results provide support for generative-evaluative learning  for dexterous grasping.