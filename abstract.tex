Dexterous grasping of a novel object given a single view is a challenging problem. Generative grasping models can be learned from demonstrations, using highly data efficient methods. The learned model can produce many candidate grasps for a target object, but gives no guarantee as to grasp success. In contrast, evaluative models, learned using data-intensive methods, have been shown to produce good predictions of grasp success. So, in this paper, we show how to combine the benefits of these two approaches in a generative-evaluative learning architecture. The generative model is learned using very data efficient learning from demonstration, and the evaluative model is trained in simulation using grasps proposed by the generative model. We show that this combination improves significantly on a pure generative model. On a data set of 49 single-views of real objects this hybrid architecture shows a grasp success rate of 77.6\% relative to a purely generative dexterous grasp method (57.1\%), while needing only ten demonstrated real grasps.