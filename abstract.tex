Dexterous grasping of a novel object given a single view is an open problem. This paper makes several contributions to its solution. First, we present a simulator for generating and testing dexterous grasps. Second we present a data set, generated by  this simulator, of 2.4 million simulated dexterous grasps of variations of 294 base objects drawn from 20 categories. Third, we present a basic architecture for generation and evaluation of dexterous grasps that may be trained in a supervised manner. Fourth, we present three different evaluative architectures, employing ResNet-50 or VGG16 as their visual backbone. Fifth, we train, and evaluate seventeen variants of generative-evaluative architectures on this simulated data set, showing improvement from 69.53\% grasp success rate to 90.49\%. Finally, we present a real robot implementation and evaluate the four most promising variants, executing 196 real robot grasps in total. We show that our best architectural variant achieves a grasp success rate of 87.8\% on real novel objects seen from a single view, improving on a baseline of 57.1\%. 

%Deep neural networks (DNNs) have been used to learn evaluative models (EMs). Given a grasp and an image, an EM indicates the probability of grasp success. Finding a grasp is then an optimisation problem on this evaluation function, searching over the grasp configuration space. This works well for pinch grasps, but it is an open question whether this approach generalises well to dexterous grasps, where the configuration space is of high dimension. An alternative is to learn a generative model (GM), which maps from images to grasps, subsequently refined by search. Factored GMs scale to high-dimensional configuration spaces, allow data-efficient learning, and generate a wide variety of grasp types, fully exploiting the possibilities of dexterous hands. But they give no guarantee as to the probability of grasp success. This paper shows the benefits of a hybrid architecture. It presents and compares multiple versions of three architectures for dexterous grasping: i) pure GM; ii) pure EM and iii) hybrid GM-EM. Extensive empirical studies were executed in both simulation and on a real robot. These show that hybrid GM-EM outperforms pure GM,  which in turn outperforms pure EM. The best performing GM-EM model achieves 87.7\% on a real robot dexterously grasping 49 novel objects in challenging poses.


%A generative-evaluative learning architecture (GEA) is presented. The generative model (GM) is acquired by data efficient learning from demonstration (LfD), and the evaluative model (EM) is trained in simulation, using grasps proposed by the generative model. When a novel object is presented the generative model proposes grasps, which are ranked by the evaluative model. Experiments show that this GEA architecture improves on a pure generative model (GM). On a challenging set of 49 real objects, GEA has a grasp success rate of 77.6\% relative to a pure GM (57.1\%). It is also shown that grasp optimisation using the EM fails to improve on grasps suggested by the GEA, worsening grasp success rate in simulation by 4.8\% against the baseline. These results provide support for generative-evaluative learning  for dexterous grasping.